#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TEKNOFEST 2025 - Model EÄŸitimi Script
ACÄ°L 11 GÃœNLÃœK PLAN - GÃœN 3-4

1. ADIM: Varyant TanÄ±ma Modeli (modern/osmanlica/sosyal/agiz)
2. ADIM: BERTurk ile Fine-tuning
3. ADIM: Model DeÄŸerlendirme
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from transformers import (
    AutoTokenizer, AutoModelForSequenceClassification,
    TrainingArguments, Trainer, pipeline
)
import torch
from torch.utils.data import Dataset
import seaborn as sns
import matplotlib.pyplot as plt
import warnings

warnings.filterwarnings('ignore')


class TurkishVariantDataset(Dataset):
    """TÃ¼rkÃ§e varyant dataset'i iÃ§in Ã¶zel Dataset sÄ±nÄ±fÄ±"""

    def __init__(self, texts, labels, tokenizer, max_length=128):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        text = str(self.texts[idx])
        label = self.labels[idx]

        # Tokenize
        encoding = self.tokenizer(
            text,
            truncation=True,
            padding='max_length',
            max_length=self.max_length,
            return_tensors='pt'
        )

        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'labels': torch.tensor(label, dtype=torch.long)
        }


class TurkishVariantClassifier:
    """TÃ¼rkÃ§e Varyant TanÄ±ma Modeli"""

    def __init__(self):
        self.model_name = "dbmdz/bert-base-turkish-cased"  # BERTurk
        self.tokenizer = None
        self.model = None
        self.label_to_id = {'modern': 0, 'osmanlica': 1, 'sosyal': 2, 'agiz': 3}
        self.id_to_label = {v: k for k, v in self.label_to_id.items()}

    def load_data(self, csv_file='turkish_variant_dataset.csv'):
        """CSV'den veriyi yÃ¼kle"""
        print("ğŸ“Š Dataset yÃ¼kleniyor...")

        df = pd.read_csv(csv_file)
        print(f"Toplam Ã¶rnek sayÄ±sÄ±: {len(df)}")
        print("\nKategori daÄŸÄ±lÄ±mÄ±:")
        print(df['etiket'].value_counts())

        # Etiketleri sayÄ±sal deÄŸerlere Ã§evir
        df['label_id'] = df['etiket'].map(self.label_to_id)

        return df

    def prepare_data(self, df, test_size=0.2):
        """Veriyi train/test olarak ayÄ±r"""
        print("ğŸ”„ Veri hazÄ±rlanÄ±yor...")

        texts = df['metin'].tolist()
        labels = df['label_id'].tolist()

        # Train-test split
        train_texts, test_texts, train_labels, test_labels = train_test_split(
            texts, labels, test_size=test_size, random_state=42, stratify=labels
        )

        print(f"EÄŸitim verisi: {len(train_texts)}")
        print(f"Test verisi: {len(test_texts)}")

        return train_texts, test_texts, train_labels, test_labels

    def initialize_model(self):
        """Model ve tokenizer'Ä± baÅŸlat"""
        print("ğŸ¤– Model yÃ¼kleniyor (BERTurk)...")

        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(
            self.model_name,
            num_labels=4  # 4 kategori: modern, osmanlica, sosyal, agiz
        )

        print("âœ… Model baÅŸarÄ±yla yÃ¼klendi!")

    def create_datasets(self, train_texts, test_texts, train_labels, test_labels):
        """PyTorch Dataset'leri oluÅŸtur"""
        train_dataset = TurkishVariantDataset(
            train_texts, train_labels, self.tokenizer
        )
        test_dataset = TurkishVariantDataset(
            test_texts, test_labels, self.tokenizer
        )

        return train_dataset, test_dataset

    def train_model(self, train_dataset, test_dataset):
        """Modeli eÄŸit"""
        print("ğŸš€ Model eÄŸitimi baÅŸlÄ±yor...")

        # EÄŸitim parametreleri (HIZLI EÄÄ°TÄ°M Ä°Ã‡Ä°N)
        training_args = TrainingArguments(
            output_dir='./turkish_variant_model',
            num_train_epochs=3,  # KÄ±sa sÃ¼re iÃ§in 3 epoch
            per_device_train_batch_size=16,
            per_device_eval_batch_size=16,
            warmup_steps=100,
            weight_decay=0.01,
            logging_dir='./logs',
            logging_steps=50,
            evaluation_strategy="epoch",
            save_strategy="epoch",
            load_best_model_at_end=True,
        )

        # Trainer oluÅŸtur
        trainer = Trainer(
            model=self.model,
            args=training_args,
            train_dataset=train_dataset,
            eval_dataset=test_dataset,
        )

        # EÄŸitimi baÅŸlat
        print("â³ EÄŸitim devam ediyor... (Bu 10-15 dakika sÃ¼rebilir)")
        trainer.train()

        # Modeli kaydet
        trainer.save_model('./turkish_variant_model')
        self.tokenizer.save_pretrained('./turkish_variant_model')

        print("âœ… Model eÄŸitimi tamamlandÄ± ve kaydedildi!")

        return trainer

    def evaluate_model(self, trainer, test_texts, test_labels):
        """Modeli deÄŸerlendir"""
        print("ğŸ“ˆ Model deÄŸerlendiriliyor...")

        # Tahmin yap
        predictions = trainer.predict(trainer.eval_dataset)
        y_pred = np.argmax(predictions.predictions, axis=1)

        # Accuracy hesapla
        accuracy = accuracy_score(test_labels, y_pred)
        print(f"ğŸ¯ Test Accuracy: {accuracy:.4f}")

        # Classification report
        print("\nğŸ“Š DetaylÄ± Performans Raporu:")
        target_names = ['modern', 'osmanlica', 'sosyal', 'agiz']
        print(classification_report(test_labels, y_pred, target_names=target_names))

        # Confusion matrix
        cm = confusion_matrix(test_labels, y_pred)
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=target_names, yticklabels=target_names)
        plt.title('Confusion Matrix')
        plt.ylabel('GerÃ§ek Etiket')
        plt.xlabel('Tahmin Edilen Etiket')
        plt.savefig('confusion_matrix.png')
        plt.show()

        return accuracy, y_pred

    def create_pipeline(self):
        """Kolay kullanÄ±m iÃ§in pipeline oluÅŸtur"""
        print("ğŸ”§ Pipeline oluÅŸturuluyor...")

        classifier = pipeline(
            "text-classification",
            model="./turkish_variant_model",
            tokenizer="./turkish_variant_model"
        )

        return classifier

    def test_examples(self, classifier):
        """Test Ã¶rnekleri ile modeli dene"""
        print("ğŸ§ª Test Ã¶rnekleri ile model deneniyor...")

        test_examples = [
            "BugÃ¼n hava Ã§ok gÃ¼zel, dÄ±ÅŸarÄ± Ã§Ä±kalÄ±m.",  # modern
            "Bu gÃ¼n hava pek hoÅŸ idi, gezintiye Ã§Ä±ktÄ±k.",  # osmanlica
            "Abi bu film baya iyi ya, kesin izle.",  # sosyal
            "Ava Ã§ok gÃ¼zel olmuÅŸ bea, Ã§Ä±kalÄ±m dÄ±ÅŸarÄ±."  # agiz
        ]

        print("\nğŸ” Tahmin SonuÃ§larÄ±:")
        print("-" * 50)

        for text in test_examples:
            result = classifier(text)
            predicted_label = result[0]['label']
            confidence = result[0]['score']

            print(f"Metin: {text}")
            print(f"Tahmin: {predicted_label} (GÃ¼ven: {confidence:.3f})")
            print("-" * 50)

    def run_full_training(self, csv_file='turkish_variant_dataset.csv'):
        """Tam eÄŸitim sÃ¼recini Ã§alÄ±ÅŸtÄ±r"""
        print("ğŸš€ TÃœRKÃ‡E VARYANT TANIMA MODELÄ° EÄÄ°TÄ°MÄ° BAÅLIYOR!")
        print("=" * 60)

        # 1. Veri yÃ¼kle
        df = self.load_data(csv_file)

        # 2. Veriyi hazÄ±rla
        train_texts, test_texts, train_labels, test_labels = self.prepare_data(df)

        # 3. Modeli baÅŸlat
        self.initialize_model()

        # 4. Dataset'leri oluÅŸtur
        train_dataset, test_dataset = self.create_datasets(
            train_texts, test_texts, train_labels, test_labels
        )

        # 5. Modeli eÄŸit
        trainer = self.train_model(train_dataset, test_dataset)

        # 6. Modeli deÄŸerlendir
        accuracy, predictions = self.evaluate_model(trainer, test_texts, test_labels)

        # 7. Pipeline oluÅŸtur
        classifier = self.create_pipeline()

        # 8. Test Ã¶rnekleri
        self.test_examples(classifier)

        print(f"\nğŸ‰ MODEL EÄÄ°TÄ°MÄ° TAMAMLANDI!")
        print(f"ğŸ“Š Final Accuracy: {accuracy:.4f}")
        print("ğŸ’¾ Model './turkish_variant_model' klasÃ¶rÃ¼ne kaydedildi")
        print("\nğŸ”¥ SONRAKÄ° ADIMLAR:")
        print("1. Ã‡eviri modÃ¼lÃ¼nÃ¼ geliÅŸtir")
        print("2. Demo arayÃ¼zÃ¼nÃ¼ hazÄ±rla")
        print("3. GitHub'a yÃ¼kle!")

        return classifier, accuracy


# HEMEN Ã‡ALIÅTIR!
if __name__ == "__main__":
    # EÄŸitimi baÅŸlat
    trainer = TurkishVariantClassifier()

    # CUDA varsa kullan (hÄ±zlandÄ±rÄ±r)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ”§ KullanÄ±lan cihaz: {device}")

    # Tam eÄŸitim sÃ¼recini Ã§alÄ±ÅŸtÄ±r
    classifier, accuracy = trainer.run_full_training()

    print("âœ… HazÄ±r! Åimdi Ã§eviri modÃ¼lÃ¼ne geÃ§ebilirsin!")