# app.py
import os
import re
import pickle
import torch
import pandas as pd
import streamlit as st
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

# =========================
# Konfig (yollar)
# =========================
DATASET_PATH = r"C:\Users\EMRULLAH\PycharmProjects\pythonProject18\data\AllDataset.csv"
VARIANT_MODEL_PATH = r"C:\Users\EMRULLAH\PycharmProjects\pythonProject18\models\variant_classifier.pkl"
MT5_MODEL_PATH = r"C:\Users\EMRULLAH\PycharmProjects\pythonProject18\models\teknodl_models\mt5_translation"
IDIOM_MODEL_PATH = r"C:\Users\EMRULLAH\PycharmProjects\pythonProject18\models\idiom_translator.pkl"
OSM_MODEL_PATH = r"C:\Users\EMRULLAH\PycharmProjects\pythonProject18\models\osmanlica_translator.pkl"
AGIZ_MODEL_PATH = r"C:\Users\EMRULLAH\PycharmProjects\pythonProject18\models\agiz_translator.pkl"

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# =========================
# Cacheâ€™li yÃ¼kleyiciler
# =========================
@st.cache_data(show_spinner=False)
def load_lookup(path):
    if not os.path.exists(path):
        return {}
    df = pd.read_csv(path, encoding="utf-8")
    df["text"] = df["text"].astype(str).str.strip().str.lower()
    df["standard"] = df["standard"].astype(str).str.strip()
    return dict(zip(df["text"], df["standard"]))

@st.cache_resource(show_spinner=False)
def load_router(path):
    with open(path, "rb") as f:
        model, vec = pickle.load(f)
    return model, vec

@st.cache_resource(show_spinner=False)
def load_mt5(path):
    if not os.path.exists(path):
        return None, None
    tok = AutoTokenizer.from_pretrained(path)
    mdl = AutoModelForSeq2SeqLM.from_pretrained(path).to(device)
    mdl.eval()
    return tok, mdl

@st.cache_resource(show_spinner=False)
def load_pickle_model(path):
    if not os.path.exists(path):
        return None
    with open(path, "rb") as f:
        return pickle.load(f)

lookup_dict = load_lookup(DATASET_PATH)
variant_model, vectorizer = load_router(VARIANT_MODEL_PATH)
tok, mt5_model = load_mt5(MT5_MODEL_PATH)
idiom_model = load_pickle_model(IDIOM_MODEL_PATH)
osm_model = load_pickle_model(OSM_MODEL_PATH)
agiz_model = load_pickle_model(AGIZ_MODEL_PATH)

# =========================
# YardÄ±mcÄ±lar
# =========================
def norm(lbl: str) -> str:
    return str(lbl).strip().lower()

def hybrid_translate(text, lookup_dict, pkl_model, mt5_tok, mt5_model, sekme_label, threshold=0.70):
    warnings = []
    translation = None

    # 1) pkl benzerlik modeli
    if pkl_model:
        out, score = pkl_model.translate(text, threshold=threshold, return_score=True)
        if out and not out.startswith("[EÅŸleÅŸme"):
            translation = out

    # 2) Dataset lookup
    t_clean = text.strip().lower()
    if t_clean in lookup_dict:
        translation = lookup_dict[t_clean]

    # 3) mT5 fallback
    if translation is None:
        if mt5_model and mt5_tok:
            inputs = mt5_tok("translate Turkish to Turkish: " + text,
                             return_tensors="pt", truncation=True, max_length=128).to(device)
            with torch.no_grad():
                out_ids = mt5_model.generate(**inputs, max_length=128, num_beams=4,
                                             no_repeat_ngram_size=3, length_penalty=1.0, early_stopping=True)
            translation = mt5_tok.decode(out_ids[0], skip_special_tokens=True).strip()
        else:
            translation = f"[ST Ã‡eviri placeholder] {text}"

    # 4) Classifier uyarÄ±sÄ±
    pred = variant_model.predict(vectorizer.transform([text]))[0]
    if norm(pred) != norm(sekme_label):
        warnings.append(f"âš  Bu cÃ¼mle **{pred}** Ã¶zelliÄŸine daha yakÄ±n gÃ¶rÃ¼nÃ¼yor.")

    return translation, warnings

def try_translate_idiom(text: str, threshold: float = 0.65):
    if idiom_model is None:
        return None, 0.0
    out, score = idiom_model.translate(text, return_score=True)
    if out and not out.startswith("[EÅŸleÅŸme") and score >= threshold:
        return out, score
    return None, score

# =========================
# UI
# =========================
st.set_page_config(page_title="AtaDil Demo", page_icon="ğŸ“œ", layout="centered")

if "page" not in st.session_state:
    st.session_state.page = "home"

if st.session_state.page == "home":
    st.title("ğŸ“œ AtaDil Projesi")
    st.write("OsmanlÄ±ca, AÄŸÄ±z ve Deyim TanÄ±ma & Ã‡eviri Sistemi")
    cols = st.columns(3)
    if cols[1].button("BaÅŸla ğŸš€", use_container_width=True):
        st.session_state.page = "main"
    if not lookup_dict:
        st.warning("Dataset lookup yÃ¼klenemedi (AllDataset.csv bulunamadÄ±).")
    if tok is None or mt5_model is None:
        st.info("mT5 modeli bulunamadÄ± â€” sadece lookup/pkl Ã§alÄ±ÅŸacak.")
    if idiom_model is None:
        st.info("Deyim modeli bulunamadÄ± â€” deyim sekmesi kÄ±sÄ±tlÄ± Ã§alÄ±ÅŸÄ±r.")
    st.stop()

st.title("ğŸ“š AtaDil Ã‡eviri ve TanÄ±ma")
tabs = st.tabs(["OsmanlÄ±ca", "AÄŸÄ±z", "Deyim"])

# -------- OsmanlÄ±ca --------
with tabs[0]:
    st.subheader("OsmanlÄ±ca â†’ Standart TÃ¼rkÃ§e")
    with st.form("osm_form", clear_on_submit=False):
        osm_text = st.text_area("CÃ¼mleyi giriniz", height=120)
        submit = st.form_submit_button("Ã‡evir (OsmanlÄ±ca)")
    if submit and osm_text.strip():
        tr, warns = hybrid_translate(osm_text, lookup_dict, osm_model, tok, mt5_model, "osmanlica")
        st.success("ğŸ“Œ TÃ¼r: **OsmanlÄ±ca**")
        st.write("**ğŸ’¬ Standart TÃ¼rkÃ§e:**")
        st.write(tr)
        for w in warns:
            st.warning(w)

# -------- AÄŸÄ±z --------
with tabs[1]:
    st.subheader("AÄŸÄ±z â†’ Standart TÃ¼rkÃ§e")
    with st.form("agiz_form", clear_on_submit=False):
        agiz_text = st.text_area("CÃ¼mleyi giriniz", height=120)
        submit = st.form_submit_button("Ã‡evir (AÄŸÄ±z)")
    if submit and agiz_text.strip():
        tr, warns = hybrid_translate(agiz_text, lookup_dict, agiz_model, tok, mt5_model, "aÄŸÄ±z")
        st.success("ğŸ“Œ TÃ¼r: **AÄŸÄ±z**")
        st.write("**ğŸ’¬ Standart TÃ¼rkÃ§e:**")
        st.write(tr)
        for w in warns:
            st.warning(w)

# -------- Deyim --------
with tabs[2]:
    st.subheader("Ä°ngilizce Deyim â†’ TÃ¼rkÃ§e")
    with st.form("deyim_form", clear_on_submit=False):
        deyim_text = st.text_area("Ä°ngilizce deyimi giriniz", placeholder="break a leg, bite the bullet ...",
                                  height=120)
        submit = st.form_submit_button("Ã‡evir (Deyim)")
    if submit and deyim_text.strip():
        if not re.fullmatch(r"[A-Za-z\s\-'â€™]+", deyim_text.strip()):
            st.error("âš  LÃ¼tfen **sadece Ä°ngilizce deyimler** giriniz.")
        else:
            out, sc = try_translate_idiom(deyim_text)
            if out:
                st.success("ğŸ“Œ TÃ¼r: **Deyim**")
                st.write("**ğŸ’¬ TÃ¼rkÃ§e KarÅŸÄ±lÄ±ÄŸÄ±:**")
                st.write(out)
            else:
                st.error("Bu ifade **deyim** deÄŸil.")
